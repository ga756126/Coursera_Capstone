
<h1>Data</h1>

This is a countrywide traffic accident dataset, which covers 49 states of the United States. The data contains details of 3.5 million traffic accidents that took place in the United States, from February 2016 to June 2020. There are 49 fields total and 10 Fields containing road and weather conditions that are in concern. Data is collected using several data providers, including two APIs which provide streaming traffic event data. These APIs broadcast traffic events captured by a variety of entities, such as the US and state departments of transportation, law enforcement agencies, traffic cameras, and traffic sensors within the road-networks.

**Source Data files:**

• US_Accidents_June20.csv: every line in the file represents a unique traffic accident (identified by the ID column), featuring various properties related to the accident as columns. Date range: February 2016 to June 2020

• CA_Accidents_2020_150k.csv : Test set for Accidents in CA to predict and validate the accuracy of the machine learning models built. Sample size is 150k records

**Description of the fields:**

| Field |  Description    |
| ----- |  -------------- |
|  ID   | <p align="left justify"> This is a unique identifier of the accident record  </p>|
|Severity| <p align="left justify"> Shows the severity of the accident, a number between 1 and 4, where 1 indicates the least impact on traffic </p>
|       |(i.e., short delay as a result of the accident) and 4 indicates a significant impact on traffic (i.e., long delay). </p>|
|Description |<p align="left justify">Shows natural language description of the accident. </p>|
|Number|<p align="left justify">Shows the street number in address record. </p>|
|Street| <p align="left justify">Shows the street name in address record. </p>|
|City| <p align="left justify">Shows the city in address record. </p>|
|County|<p align="left justify"> Shows the county in address record. </p>|
|State| <p align="left justify">Shows the state in address record. </p>||
|Zipcode|<p align="left justify"> Shows the zipcode in address record. </p>|
|Country| <p align="left justify">Shows the country in address record. </p>|
|Temperature(F)|<p align="left justify"> Shows the temperature (in Fahrenheit). </p>|
|Wind_Chill(F)| <p align="left justify">Shows the wind chill (in Fahrenheit). </p>|
|Humidity(%)| <p align="left justify">Shows the humidity (in percene). </p>|
|Pressure(in)|<p align="left justify"> Shows the air pressure (in inches). </p>|
|Visibility(mi)|<p align="left justify"> Shows visibility (in miles). </p>|
|Wind_Direction| <p align="left justify">Shows wind direction. </p>|
|Wind_Speed(mph)|<p align="left justify">Shows wind speed (in miles per hour). </p>|
|Precipitation(in) |<p align="left justify"> Shows precipitation amount in inches, if there is any. </p>|
|Weather_Condition| <p align="left justify">Shows the weather condition (rain, snow, thunderstorm, fog, etc.) </p>|
|Sunrise_Sunset| <p align="left justify">Shows the period of day (i.e. day or night) based on sunrise/sunset. </p>|

<h1>Approach</h1>

Since there are 3.5 Million records abd 49 features the data is sampled to 700K observations and 20 essential features.  

Independent Variables selected:  
>Temperature(F)  
>Wind_Chill(F)  
>Humidity(%)  
>Pressure(in)  
>Visibility(mi)  
>Wind_Direction  
>Wind_Speed(mph)  
>Precipitation(in)  
>Weather_Condition  
>Sunrise_Sunset  


Dependent Variables: 
>Severity (1 - 4)

*Note: For the interest of the audience the Severity will be categorized in to severe (Severity > 2) and slight (Severity =< 2) as it is assumed to be more comprehensible.*  

**Data preparation**  
• Load data  
• Sample the data   
• Pre-Process the data Check for missing values (NaN) Exploratory Visualization Data Normalization Convert any categorical features to numerical values (Hot encode if need)  
• Feature selection

**Data split**   
• Split the data into Train set and test set

**Classification Models:**  
• Decision Tree  
• Logistic Regression (Solver = 'saga' on larger datasets. Reference:https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451 )

**Predict and Validate Models**  
• Load data (CA_Accidents_2020_150k.csv)  
• Pre-Process the data  
• Create predictions using the classification models above  
• Validate the accuracy of the models using applicable indexes Jaccard index F1-score LogLoss
